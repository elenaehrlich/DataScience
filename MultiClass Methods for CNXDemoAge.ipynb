{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiClass Methods for CNXDemo Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "# Python libraries & settings preamble\n",
    "################################################\n",
    "import binascii\n",
    "from cycler import cycler\n",
    "import datetime\n",
    "from IPython.display import Image #Image(filename='//Users//161751//Desktop//Lion_Pride.jpg')\n",
    "from IPython.display import display\n",
    "import itertools\n",
    "#import locale\n",
    "#locale.setlocale(locale.LC_ALL, 'en_US')\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import numpy.matlib\n",
    "import os\n",
    "import pandas\n",
    "from pandas.tools.util import cartesian_product\n",
    "from pg import DB\n",
    "import plotly.plotly as py\n",
    "py.sign_in('mathsmodel', 'zcwivinavl')\n",
    "import plotly.graph_objs as go\n",
    "import pylab\n",
    "from pylab import rcParams\n",
    "import re\n",
    "import seaborn\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import sys\n",
    "import urllib\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pylab.ion()\n",
    "\n",
    "\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "matplotlib.rcParams.update({'font.size': 10})\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 10}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('axes', labelsize='large')\n",
    "matplotlib.rc('axes', titlesize='large')\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "def intWithCommas(x):\n",
    "    if type(x) not in [type(0), type(0L)]:\n",
    "        raise TypeError(\"Parameter must be an integer.\")\n",
    "    if x < 0:\n",
    "        return '-' + intWithCommas(-x)\n",
    "    result = ''\n",
    "    while x >= 1000:\n",
    "        x, r = divmod(x, 1000)\n",
    "        result = \",%03d%s\" % (r, result)\n",
    "    return \"%d%s\" % (x, result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Training, Validation, and OOS Sets\n",
    "\n",
    "TOPIC: CNXDemo Age\n",
    "\n",
    "ETS: merged\n",
    "\n",
    "FEATURES: Hashed ~180,000 --> 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training = pandas.read_csv(\"mergedETS_training_featuresHashed.tsv\", index_col=0, header=None)\n",
    "#validation = pandas.read_csv(\"mergedETS_validation_featuresHashed.tsv\", index_col=0, header=None)\n",
    "ets = pandas.read_csv('mergedETS_featuresHashed.tsv', header=None, index_col=0)\n",
    "\n",
    "t = pandas.read_csv('/home/cxt/spark/multinomial-uids/training.txt', header=None).as_matrix().ravel()\n",
    "v = pandas.read_csv('/home/cxt/spark/multinomial-uids/validation.txt', header=None).as_matrix().ravel()\n",
    "training = ets.loc[t].copy()\n",
    "validation = ets.loc[v].copy()\n",
    "\n",
    "training_labels = training[1]\n",
    "training_features = training[training.columns[1:]]\n",
    "\n",
    "validation_labels = validation[1]\n",
    "validation_features = validation[validation.columns[1:]]\n",
    "#del ets\n",
    "\n",
    "how_wrong_can_we_classify_user = pandas.read_csv('how_wrong_can_we_classify_user.tsv').drop('Pred Bucket',axis=1)\n",
    "#efficacy_validation = pandas.DataFrame(0, columns=['NBbernoulli','LDA','NBgaussian','NBmultinomial'], index=['accuracy','weighted-error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_xid_tkid_age = pandas.DataFrame([[672,11349,21],\n",
    "[673,11350,27],\n",
    "[674,11351,32],\n",
    "[675,11352,37],\n",
    "[676,11353,42],\n",
    "[677,11354,47],\n",
    "[678,11355,52],\n",
    "[679,11356,57],\n",
    "[680,11357,62],\n",
    "[681,11358,71]], columns=['tkid','xid','age']).set_index('xid')\n",
    "oos = pandas.read_csv('oos_featuresHashed.tsv', header=None)\n",
    "oos_labels = map_xid_tkid_age.loc[oos[0]]['tkid'].ravel()\n",
    "oos_features = oos[oos.columns[1:]]\n",
    "\n",
    "#efficacy_oos = pandas.DataFrame(0, columns=['NBbernoulli','LDA','NBgaussian','NBmultinomial'], index=['accuracy','weighted-error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "11349    0.067775\n",
       "11350    0.079607\n",
       "11351    0.093748\n",
       "11352    0.090230\n",
       "11353    0.087450\n",
       "11354    0.094080\n",
       "11355    0.108350\n",
       "11356    0.105695\n",
       "11357    0.105444\n",
       "11358    0.167620\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos.groupby(0).size() / float(oos.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: Naive Bayes Bernoulli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29323144738\n"
     ]
    }
   ],
   "source": [
    "nb_bernoulli = BernoulliNB()\n",
    "nb_bernoulli.fit(training_features, training_labels)\n",
    "\n",
    "validation_pred = nb_bernoulli.predict(validation_features)\n",
    "accuracy = nb_bernoulli.score(validation_features, validation_labels)\n",
    "print(accuracy)\n",
    "\n",
    "alg = \"NBbernoulli\"\n",
    "uids = pandas.DataFrame(validation_labels, columns=['true']).join(pandas.DataFrame(validation_pred,columns=['pred'])) \n",
    "counts = uids.groupby(['true','pred']).size().unstack().transpose()\n",
    "c = counts.reset_index(drop=True).transpose().reset_index(drop=True).transpose() \n",
    "distance_error_counts = how_wrong_can_we_classify_user.reset_index(drop=True).transpose().reset_index(drop=True).transpose().multiply(c)\n",
    "distance_error = distance_error_counts.sum().sum()/counts.sum().sum()\n",
    "efficacy_validation.loc['accuracy',alg] = accuracy\n",
    "efficacy_validation.loc['weighted-error',alg] = distance_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "lda.fit(training_features, training_labels)\n",
    "\n",
    "validation_pred = lda.predict(validation_features)\n",
    "accuracy = lda.score(validation_features,validation_labels)\n",
    "print(accuracy)\n",
    "\n",
    "alg = \"LDA\"\n",
    "uids = pandas.DataFrame(validation_labels, columns=['true']).join(pandas.DataFrame(validation_pred,columns=['pred'])) \n",
    "counts = uids.groupby(['true','pred']).size().unstack().transpose()\n",
    "c = counts.reset_index(drop=True).transpose().reset_index(drop=True).transpose() \n",
    "distance_error_counts = how_wrong_can_we_classify_user.reset_index(drop=True).transpose().reset_index(drop=True).transpose().multiply(c)\n",
    "distance_error = distance_error_counts.sum().sum()/counts.sum().sum()\n",
    "efficacy_validation.loc['accuracy',alg] = accuracy\n",
    "efficacy_validation.loc['weighted-error',alg] = distance_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=training_features.shape[1])\n",
    "pca.fit(training_features)\n",
    "#plt.figure()\n",
    "#plt.bar(numpy.arange(training_features.shape[1]), numpy.cumsum(pca.explained_variance_ratio_))\n",
    "#plt.xlabel('Component')\n",
    "#plt.ylabel('Explained Variance Ratio')\n",
    "\n",
    "training_transformed = pca.transform(training_features)\n",
    "validation_transformed = pca.transform(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.074278</td>\n",
       "      <td>0.088570</td>\n",
       "      <td>0.271287</td>\n",
       "      <td>-0.023725</td>\n",
       "      <td>-0.094105</td>\n",
       "      <td>-0.136623</td>\n",
       "      <td>-0.011198</td>\n",
       "      <td>-0.011292</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.101774</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020795</td>\n",
       "      <td>-0.000482</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.033718</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>-0.009493</td>\n",
       "      <td>0.402715</td>\n",
       "      <td>-0.105636</td>\n",
       "      <td>-0.646764</td>\n",
       "      <td>-0.013882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.104350</td>\n",
       "      <td>0.133818</td>\n",
       "      <td>-0.129681</td>\n",
       "      <td>-0.080979</td>\n",
       "      <td>-0.057142</td>\n",
       "      <td>-0.110781</td>\n",
       "      <td>0.110550</td>\n",
       "      <td>0.055610</td>\n",
       "      <td>-0.018507</td>\n",
       "      <td>0.101492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>-0.002480</td>\n",
       "      <td>-0.020893</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.018042</td>\n",
       "      <td>-0.012318</td>\n",
       "      <td>0.009280</td>\n",
       "      <td>0.003229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.071304</td>\n",
       "      <td>-0.048105</td>\n",
       "      <td>-0.037445</td>\n",
       "      <td>-0.064261</td>\n",
       "      <td>-0.048046</td>\n",
       "      <td>-0.027074</td>\n",
       "      <td>-0.090486</td>\n",
       "      <td>-0.006436</td>\n",
       "      <td>-0.050081</td>\n",
       "      <td>-0.032147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>-0.003136</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>-0.008178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.064023</td>\n",
       "      <td>-0.080124</td>\n",
       "      <td>-0.022189</td>\n",
       "      <td>-0.023991</td>\n",
       "      <td>-0.007230</td>\n",
       "      <td>-0.022722</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>-0.057324</td>\n",
       "      <td>-0.011524</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>-0.011253</td>\n",
       "      <td>-0.003600</td>\n",
       "      <td>-0.009001</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>-0.010099</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.003835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.099983</td>\n",
       "      <td>0.035365</td>\n",
       "      <td>-0.052276</td>\n",
       "      <td>-0.011954</td>\n",
       "      <td>0.034217</td>\n",
       "      <td>0.062766</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>-0.071361</td>\n",
       "      <td>-0.003909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169632</td>\n",
       "      <td>0.289181</td>\n",
       "      <td>0.064872</td>\n",
       "      <td>0.125424</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>-0.020019</td>\n",
       "      <td>-0.044315</td>\n",
       "      <td>0.011130</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.001121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.074278  0.088570  0.271287 -0.023725 -0.094105 -0.136623 -0.011198   \n",
       "1 -0.104350  0.133818 -0.129681 -0.080979 -0.057142 -0.110781  0.110550   \n",
       "2 -0.071304 -0.048105 -0.037445 -0.064261 -0.048046 -0.027074 -0.090486   \n",
       "3 -0.064023 -0.080124 -0.022189 -0.023991 -0.007230 -0.022722  0.002701   \n",
       "4 -0.099983  0.035365 -0.052276 -0.011954  0.034217  0.062766  0.007102   \n",
       "\n",
       "        7         8         9      ...          246       247       248  \\\n",
       "0 -0.011292  0.024024  0.101774    ...    -0.020795 -0.000482  0.008545   \n",
       "1  0.055610 -0.018507  0.101492    ...     0.002882 -0.002480 -0.020893   \n",
       "2 -0.006436 -0.050081 -0.032147    ...     0.007272  0.000412  0.008902   \n",
       "3 -0.057324 -0.011524  0.024962    ...     0.001392  0.002433  0.004055   \n",
       "4  0.003635 -0.071361 -0.003909    ...    -0.169632  0.289181  0.064872   \n",
       "\n",
       "        249       250       251       252       253       254       255  \n",
       "0  0.033718  0.002651 -0.009493  0.402715 -0.105636 -0.646764 -0.013882  \n",
       "1  0.005431  0.004285  0.004494  0.018042 -0.012318  0.009280  0.003229  \n",
       "2 -0.003136  0.001101  0.000272 -0.002041  0.008749 -0.001739 -0.008178  \n",
       "3 -0.011253 -0.003600 -0.009001  0.005132 -0.010099  0.003127  0.003835  \n",
       "4  0.125424  0.004668 -0.020019 -0.044315  0.011130  0.002360  0.001121  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principle_components = pandas.DataFrame(pca.components_).transpose()\n",
    "print(principle_components.shape)\n",
    "principle_components.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca.components_ = pca.components_ * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275396, 256)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20156320856149863</th>\n",
       "      <td>1.292196</td>\n",
       "      <td>-1.414736</td>\n",
       "      <td>-0.865697</td>\n",
       "      <td>-0.107149</td>\n",
       "      <td>0.095529</td>\n",
       "      <td>-0.815595</td>\n",
       "      <td>0.629699</td>\n",
       "      <td>0.449353</td>\n",
       "      <td>-1.597152</td>\n",
       "      <td>0.276497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047981</td>\n",
       "      <td>-0.007549</td>\n",
       "      <td>-0.059181</td>\n",
       "      <td>-0.130107</td>\n",
       "      <td>0.069376</td>\n",
       "      <td>-0.151251</td>\n",
       "      <td>0.146924</td>\n",
       "      <td>-0.115643</td>\n",
       "      <td>0.082727</td>\n",
       "      <td>-0.020595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16221703785943514</th>\n",
       "      <td>1.079409</td>\n",
       "      <td>-1.289207</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>-1.404979</td>\n",
       "      <td>0.899182</td>\n",
       "      <td>0.179987</td>\n",
       "      <td>0.613738</td>\n",
       "      <td>0.332901</td>\n",
       "      <td>-0.189126</td>\n",
       "      <td>0.216958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105014</td>\n",
       "      <td>0.049927</td>\n",
       "      <td>-0.555613</td>\n",
       "      <td>0.373425</td>\n",
       "      <td>0.023921</td>\n",
       "      <td>-0.348361</td>\n",
       "      <td>-0.161817</td>\n",
       "      <td>-0.088779</td>\n",
       "      <td>-0.096491</td>\n",
       "      <td>0.047944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23184125582168755</th>\n",
       "      <td>0.640578</td>\n",
       "      <td>0.341507</td>\n",
       "      <td>-0.491820</td>\n",
       "      <td>1.393423</td>\n",
       "      <td>-0.119867</td>\n",
       "      <td>1.901982</td>\n",
       "      <td>-0.646612</td>\n",
       "      <td>-0.937447</td>\n",
       "      <td>-0.635041</td>\n",
       "      <td>0.267789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216040</td>\n",
       "      <td>0.222657</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.147877</td>\n",
       "      <td>0.065992</td>\n",
       "      <td>-0.058447</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.075637</td>\n",
       "      <td>0.044501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23272004138357351</th>\n",
       "      <td>-2.638846</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>-0.874967</td>\n",
       "      <td>0.044859</td>\n",
       "      <td>-0.773818</td>\n",
       "      <td>0.255232</td>\n",
       "      <td>0.189929</td>\n",
       "      <td>-0.117071</td>\n",
       "      <td>-0.028746</td>\n",
       "      <td>0.327853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>-0.015949</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>-0.022696</td>\n",
       "      <td>0.032951</td>\n",
       "      <td>-0.465394</td>\n",
       "      <td>0.145721</td>\n",
       "      <td>0.247518</td>\n",
       "      <td>0.004737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17804354130069208</th>\n",
       "      <td>-0.561183</td>\n",
       "      <td>0.543986</td>\n",
       "      <td>0.692097</td>\n",
       "      <td>-2.359414</td>\n",
       "      <td>0.444011</td>\n",
       "      <td>0.184647</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>-0.908948</td>\n",
       "      <td>0.440048</td>\n",
       "      <td>-1.233005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087059</td>\n",
       "      <td>-0.351251</td>\n",
       "      <td>-0.154111</td>\n",
       "      <td>-0.168031</td>\n",
       "      <td>0.012674</td>\n",
       "      <td>-0.223685</td>\n",
       "      <td>0.424829</td>\n",
       "      <td>-0.277871</td>\n",
       "      <td>-0.665473</td>\n",
       "      <td>-0.036420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5    \\\n",
       "0                                                                               \n",
       "20156320856149863  1.292196 -1.414736 -0.865697 -0.107149  0.095529 -0.815595   \n",
       "16221703785943514  1.079409 -1.289207  0.032034 -1.404979  0.899182  0.179987   \n",
       "23184125582168755  0.640578  0.341507 -0.491820  1.393423 -0.119867  1.901982   \n",
       "23272004138357351 -2.638846  0.579952 -0.874967  0.044859 -0.773818  0.255232   \n",
       "17804354130069208 -0.561183  0.543986  0.692097 -2.359414  0.444011  0.184647   \n",
       "\n",
       "                        6         7         8         9      ...          246  \\\n",
       "0                                                            ...                \n",
       "20156320856149863  0.629699  0.449353 -1.597152  0.276497    ...     0.047981   \n",
       "16221703785943514  0.613738  0.332901 -0.189126  0.216958    ...     0.105014   \n",
       "23184125582168755 -0.646612 -0.937447 -0.635041  0.267789    ...    -0.216040   \n",
       "23272004138357351  0.189929 -0.117071 -0.028746  0.327853    ...     0.020204   \n",
       "17804354130069208 -0.003125 -0.908948  0.440048 -1.233005    ...     0.087059   \n",
       "\n",
       "                        247       248       249       250       251       252  \\\n",
       "0                                                                               \n",
       "20156320856149863 -0.007549 -0.059181 -0.130107  0.069376 -0.151251  0.146924   \n",
       "16221703785943514  0.049927 -0.555613  0.373425  0.023921 -0.348361 -0.161817   \n",
       "23184125582168755  0.222657  0.007174  0.147877  0.065992 -0.058447  0.119141   \n",
       "23272004138357351 -0.015949  0.005241 -0.000359 -0.022696  0.032951 -0.465394   \n",
       "17804354130069208 -0.351251 -0.154111 -0.168031  0.012674 -0.223685  0.424829   \n",
       "\n",
       "                        253       254       255  \n",
       "0                                                \n",
       "20156320856149863 -0.115643  0.082727 -0.020595  \n",
       "16221703785943514 -0.088779 -0.096491  0.047944  \n",
       "23184125582168755  0.012783  0.075637  0.044501  \n",
       "23272004138357351  0.145721  0.247518  0.004737  \n",
       "17804354130069208 -0.277871 -0.665473 -0.036420  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pandas.DataFrame(training_transformed).shape)\n",
    "pandas.DataFrame(training_transformed, index=training_features.index).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276164, 256)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9288284844333351</th>\n",
       "      <td>3.849054</td>\n",
       "      <td>-0.147213</td>\n",
       "      <td>0.303542</td>\n",
       "      <td>-0.009842</td>\n",
       "      <td>-0.422465</td>\n",
       "      <td>-0.565225</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>1.276933</td>\n",
       "      <td>-0.915168</td>\n",
       "      <td>-0.322446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207194</td>\n",
       "      <td>0.209830</td>\n",
       "      <td>-0.613508</td>\n",
       "      <td>0.241852</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>-0.404010</td>\n",
       "      <td>-0.098714</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>-0.056288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20722957809749969</th>\n",
       "      <td>-2.708751</td>\n",
       "      <td>-0.105384</td>\n",
       "      <td>-0.097898</td>\n",
       "      <td>0.413972</td>\n",
       "      <td>-0.095751</td>\n",
       "      <td>-0.784123</td>\n",
       "      <td>0.144042</td>\n",
       "      <td>-0.368362</td>\n",
       "      <td>0.204037</td>\n",
       "      <td>-0.265425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053330</td>\n",
       "      <td>-0.030823</td>\n",
       "      <td>-0.047515</td>\n",
       "      <td>-0.056143</td>\n",
       "      <td>-0.009126</td>\n",
       "      <td>0.011423</td>\n",
       "      <td>-0.625218</td>\n",
       "      <td>0.143581</td>\n",
       "      <td>0.144589</td>\n",
       "      <td>0.025588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23207904112410946</th>\n",
       "      <td>-0.693783</td>\n",
       "      <td>-1.007255</td>\n",
       "      <td>-0.192161</td>\n",
       "      <td>0.811852</td>\n",
       "      <td>0.799170</td>\n",
       "      <td>-1.119624</td>\n",
       "      <td>0.680558</td>\n",
       "      <td>-0.121710</td>\n",
       "      <td>-1.010267</td>\n",
       "      <td>-0.364271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090982</td>\n",
       "      <td>0.151331</td>\n",
       "      <td>0.030990</td>\n",
       "      <td>0.060757</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>-0.056676</td>\n",
       "      <td>-0.116892</td>\n",
       "      <td>0.061647</td>\n",
       "      <td>-0.099041</td>\n",
       "      <td>-0.027580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8438939060540919</th>\n",
       "      <td>2.197646</td>\n",
       "      <td>-0.211044</td>\n",
       "      <td>-0.605976</td>\n",
       "      <td>-0.481092</td>\n",
       "      <td>-1.223206</td>\n",
       "      <td>0.322992</td>\n",
       "      <td>0.748968</td>\n",
       "      <td>0.807298</td>\n",
       "      <td>-0.134348</td>\n",
       "      <td>-0.530814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080648</td>\n",
       "      <td>-0.312088</td>\n",
       "      <td>-0.052590</td>\n",
       "      <td>-0.214522</td>\n",
       "      <td>-0.030994</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.201142</td>\n",
       "      <td>0.901881</td>\n",
       "      <td>0.150124</td>\n",
       "      <td>0.038140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23051156318899201</th>\n",
       "      <td>-3.225811</td>\n",
       "      <td>0.381363</td>\n",
       "      <td>0.292191</td>\n",
       "      <td>0.663757</td>\n",
       "      <td>0.106623</td>\n",
       "      <td>-0.515320</td>\n",
       "      <td>-0.210134</td>\n",
       "      <td>-0.395549</td>\n",
       "      <td>-0.448635</td>\n",
       "      <td>0.656283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003453</td>\n",
       "      <td>0.020852</td>\n",
       "      <td>-0.027991</td>\n",
       "      <td>-0.032445</td>\n",
       "      <td>-0.023354</td>\n",
       "      <td>0.015952</td>\n",
       "      <td>-0.299039</td>\n",
       "      <td>0.083732</td>\n",
       "      <td>0.590513</td>\n",
       "      <td>0.011559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5    \\\n",
       "0                                                                               \n",
       "9288284844333351   3.849054 -0.147213  0.303542 -0.009842 -0.422465 -0.565225   \n",
       "20722957809749969 -2.708751 -0.105384 -0.097898  0.413972 -0.095751 -0.784123   \n",
       "23207904112410946 -0.693783 -1.007255 -0.192161  0.811852  0.799170 -1.119624   \n",
       "8438939060540919   2.197646 -0.211044 -0.605976 -0.481092 -1.223206  0.322992   \n",
       "23051156318899201 -3.225811  0.381363  0.292191  0.663757  0.106623 -0.515320   \n",
       "\n",
       "                        6         7         8         9      ...          246  \\\n",
       "0                                                            ...                \n",
       "9288284844333351   0.177899  1.276933 -0.915168 -0.322446    ...    -0.207194   \n",
       "20722957809749969  0.144042 -0.368362  0.204037 -0.265425    ...     0.053330   \n",
       "23207904112410946  0.680558 -0.121710 -1.010267 -0.364271    ...    -0.090982   \n",
       "8438939060540919   0.748968  0.807298 -0.134348 -0.530814    ...     0.080648   \n",
       "23051156318899201 -0.210134 -0.395549 -0.448635  0.656283    ...    -0.003453   \n",
       "\n",
       "                        247       248       249       250       251       252  \\\n",
       "0                                                                               \n",
       "9288284844333351   0.209830 -0.613508  0.241852  0.102900 -0.404010 -0.098714   \n",
       "20722957809749969 -0.030823 -0.047515 -0.056143 -0.009126  0.011423 -0.625218   \n",
       "23207904112410946  0.151331  0.030990  0.060757  0.000626 -0.056676 -0.116892   \n",
       "8438939060540919  -0.312088 -0.052590 -0.214522 -0.030994  0.004178  0.201142   \n",
       "23051156318899201  0.020852 -0.027991 -0.032445 -0.023354  0.015952 -0.299039   \n",
       "\n",
       "                        253       254       255  \n",
       "0                                                \n",
       "9288284844333351  -0.001022  0.016137 -0.056288  \n",
       "20722957809749969  0.143581  0.144589  0.025588  \n",
       "23207904112410946  0.061647 -0.099041 -0.027580  \n",
       "8438939060540919   0.901881  0.150124  0.038140  \n",
       "23051156318899201  0.083732  0.590513  0.011559  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pandas.DataFrame(validation_transformed).shape)\n",
    "pandas.DataFrame(validation_transformed, index=validation_features.index).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (after PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.114341141385\n"
     ]
    }
   ],
   "source": [
    "validation_pred = lda.predict(validation_transformed)\n",
    "accuracy = lda.score(validation_transformed,validation_labels)\n",
    "print(accuracy)\n",
    "\n",
    "alg = \"LDApca\"\n",
    "uids = pandas.DataFrame(validation_labels, columns=['true']).join(pandas.DataFrame(validation_pred,columns=['pred'])) \n",
    "counts = uids.groupby(['true','pred']).size().unstack().transpose()\n",
    "c = counts.reset_index(drop=True).transpose().reset_index(drop=True).transpose() \n",
    "distance_error_counts = how_wrong_can_we_classify_user.reset_index(drop=True).transpose().reset_index(drop=True).transpose().multiply(c)\n",
    "distance_error = distance_error_counts.sum().sum()/counts.sum().sum()\n",
    "efficacy_validation.loc['accuracy',alg] = accuracy\n",
    "efficacy_validation.loc['weighted-error',alg] = distance_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: Naive Bayes Gaussian (after PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_gaussian_pca = GaussianNB()\n",
    "nb_gaussian_pca.fit(training_transformed, training_labels)\n",
    "\n",
    "validation_pred = nb_gaussian_pca.predict(validation_transformed)\n",
    "accuracy = nb_gaussian_pca.score(validation_transformed, validation_labels)\n",
    "\n",
    "alg = \"NBgaussian\"\n",
    "uids = pandas.DataFrame(validation_labels, columns=['true']).join(pandas.DataFrame(validation_pred,columns=['pred'])) \n",
    "counts = uids.groupby(['true','pred']).size().unstack().transpose()\n",
    "c = counts.reset_index(drop=True).transpose().reset_index(drop=True).transpose() \n",
    "distance_error_counts = how_wrong_can_we_classify_user.reset_index(drop=True).transpose().reset_index(drop=True).transpose().multiply(c)\n",
    "distance_error = distance_error_counts.sum().sum()/counts.sum().sum()\n",
    "efficacy_validation.loc['accuracy',alg] = accuracy\n",
    "efficacy_validation.loc['weighted-error',alg] = distance_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: Naive Bayes Multinomial (after PCA)\n",
    "\n",
    "Map the real-valued (gaussian) components to positive-integer (multinomial) components, while maintaining their correct probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f234545cc90>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0sAAAGOCAYAAABG/phYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f23c8f85c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2AAAAGOCAYAAADxQ2B/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2294841650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = pandas.DataFrame(training_transformed)[0]\n",
    "plt.hist(f, bins=1000, normed=True);\n",
    "plt.xlabel('1st projected component')\n",
    "plt.ylabel('pdf(x)')\n",
    "plt.title('Gaussian')\n",
    "\n",
    "gamma = 1000./numpy.var(f)\n",
    "fmin = numpy.min(f)\n",
    "z = numpy.floor((f-fmin)*gamma)\n",
    "plt.figure()\n",
    "plt.hist(z, bins=numpy.arange(numpy.max(z)), normed=True);\n",
    "plt.xlabel('1st projected component')\n",
    "plt.ylabel('pmf(z)')\n",
    "plt.title('Multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value of each projected component sorted descending:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255   -0.372968\n",
       "253   -0.725135\n",
       "251   -0.808249\n",
       "252   -0.928738\n",
       "254   -0.943782\n",
       "248   -1.150766\n",
       "235   -1.173624\n",
       "246   -1.188375\n",
       "249   -1.194732\n",
       "236   -1.204279\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of each projected component sorted descending:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    7.546691\n",
       "1    0.867504\n",
       "2    0.635634\n",
       "3    0.539353\n",
       "4    0.507489\n",
       "5    0.454196\n",
       "6    0.421450\n",
       "7    0.407392\n",
       "8    0.364975\n",
       "9    0.314452\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_z = pandas.DataFrame(training_transformed, index=training_features.index).apply(lambda x: numpy.floor((x-x.min())*(1000./x.var()))) \n",
    "validation_z = pandas.DataFrame(validation_transformed, index=validation_features.index).apply(lambda x: numpy.floor((x-x.min())*(1000./x.var()))) \n",
    "\n",
    "xmin = pandas.DataFrame(training_transformed).apply(lambda x: x.min())\n",
    "print('Minimum value of each projected component sorted descending:')\n",
    "display(xmin.sort_values(ascending=False)[:10])\n",
    "\n",
    "xvar = pandas.DataFrame(training_transformed).apply(lambda x: x.var())\n",
    "print('Variance of each projected component sorted descending:')\n",
    "display(xvar.sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20156320856149863</th>\n",
       "      <td>663.0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>5112.0</td>\n",
       "      <td>5803.0</td>\n",
       "      <td>3938.0</td>\n",
       "      <td>8169.0</td>\n",
       "      <td>6796.0</td>\n",
       "      <td>2426.0</td>\n",
       "      <td>8243.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24201.0</td>\n",
       "      <td>23875.0</td>\n",
       "      <td>22049.0</td>\n",
       "      <td>21789.0</td>\n",
       "      <td>27420.0</td>\n",
       "      <td>14257.0</td>\n",
       "      <td>24984.0</td>\n",
       "      <td>14282.0</td>\n",
       "      <td>31291.0</td>\n",
       "      <td>34593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16221703785943514</th>\n",
       "      <td>635.0</td>\n",
       "      <td>1855.0</td>\n",
       "      <td>4143.0</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>7386.0</td>\n",
       "      <td>6130.0</td>\n",
       "      <td>8131.0</td>\n",
       "      <td>6511.0</td>\n",
       "      <td>6283.0</td>\n",
       "      <td>8053.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25317.0</td>\n",
       "      <td>25013.0</td>\n",
       "      <td>12021.0</td>\n",
       "      <td>32095.0</td>\n",
       "      <td>26467.0</td>\n",
       "      <td>9980.0</td>\n",
       "      <td>17813.0</td>\n",
       "      <td>14912.0</td>\n",
       "      <td>25828.0</td>\n",
       "      <td>41321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23184125582168755</th>\n",
       "      <td>577.0</td>\n",
       "      <td>3735.0</td>\n",
       "      <td>3318.0</td>\n",
       "      <td>7894.0</td>\n",
       "      <td>5378.0</td>\n",
       "      <td>9922.0</td>\n",
       "      <td>5141.0</td>\n",
       "      <td>3392.0</td>\n",
       "      <td>5062.0</td>\n",
       "      <td>8215.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19033.0</td>\n",
       "      <td>28433.0</td>\n",
       "      <td>23389.0</td>\n",
       "      <td>27479.0</td>\n",
       "      <td>27349.0</td>\n",
       "      <td>16271.0</td>\n",
       "      <td>24339.0</td>\n",
       "      <td>17292.0</td>\n",
       "      <td>31075.0</td>\n",
       "      <td>40983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23272004138357351</th>\n",
       "      <td>142.0</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>2716.0</td>\n",
       "      <td>5393.0</td>\n",
       "      <td>4090.0</td>\n",
       "      <td>6296.0</td>\n",
       "      <td>7126.0</td>\n",
       "      <td>5406.0</td>\n",
       "      <td>6723.0</td>\n",
       "      <td>8406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23657.0</td>\n",
       "      <td>23709.0</td>\n",
       "      <td>23350.0</td>\n",
       "      <td>24445.0</td>\n",
       "      <td>25489.0</td>\n",
       "      <td>18255.0</td>\n",
       "      <td>10762.0</td>\n",
       "      <td>20407.0</td>\n",
       "      <td>36315.0</td>\n",
       "      <td>37080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17804354130069208</th>\n",
       "      <td>417.0</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>5181.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>6489.0</td>\n",
       "      <td>6140.0</td>\n",
       "      <td>6668.0</td>\n",
       "      <td>3462.0</td>\n",
       "      <td>8007.0</td>\n",
       "      <td>3442.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24966.0</td>\n",
       "      <td>17071.0</td>\n",
       "      <td>20131.0</td>\n",
       "      <td>21013.0</td>\n",
       "      <td>26231.0</td>\n",
       "      <td>12685.0</td>\n",
       "      <td>31439.0</td>\n",
       "      <td>10481.0</td>\n",
       "      <td>8483.0</td>\n",
       "      <td>33039.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0       1       2       3       4       5       6    \\\n",
       "0                                                                          \n",
       "20156320856149863  663.0  1710.0  2730.0  5112.0  5803.0  3938.0  8169.0   \n",
       "16221703785943514  635.0  1855.0  4143.0  2705.0  7386.0  6130.0  8131.0   \n",
       "23184125582168755  577.0  3735.0  3318.0  7894.0  5378.0  9922.0  5141.0   \n",
       "23272004138357351  142.0  4010.0  2716.0  5393.0  4090.0  6296.0  7126.0   \n",
       "17804354130069208  417.0  3968.0  5181.0   936.0  6489.0  6140.0  6668.0   \n",
       "\n",
       "                      7       8       9     ...         246      247      248  \\\n",
       "0                                           ...                                 \n",
       "20156320856149863  6796.0  2426.0  8243.0   ...     24201.0  23875.0  22049.0   \n",
       "16221703785943514  6511.0  6283.0  8053.0   ...     25317.0  25013.0  12021.0   \n",
       "23184125582168755  3392.0  5062.0  8215.0   ...     19033.0  28433.0  23389.0   \n",
       "23272004138357351  5406.0  6723.0  8406.0   ...     23657.0  23709.0  23350.0   \n",
       "17804354130069208  3462.0  8007.0  3442.0   ...     24966.0  17071.0  20131.0   \n",
       "\n",
       "                       249      250      251      252      253      254  \\\n",
       "0                                                                         \n",
       "20156320856149863  21789.0  27420.0  14257.0  24984.0  14282.0  31291.0   \n",
       "16221703785943514  32095.0  26467.0   9980.0  17813.0  14912.0  25828.0   \n",
       "23184125582168755  27479.0  27349.0  16271.0  24339.0  17292.0  31075.0   \n",
       "23272004138357351  24445.0  25489.0  18255.0  10762.0  20407.0  36315.0   \n",
       "17804354130069208  21013.0  26231.0  12685.0  31439.0  10481.0   8483.0   \n",
       "\n",
       "                       255  \n",
       "0                           \n",
       "20156320856149863  34593.0  \n",
       "16221703785943514  41321.0  \n",
       "23184125582168755  40983.0  \n",
       "23272004138357351  37080.0  \n",
       "17804354130069208  33039.0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9288284844333351</th>\n",
       "      <td>1003.0</td>\n",
       "      <td>3170.0</td>\n",
       "      <td>4629.0</td>\n",
       "      <td>4852.0</td>\n",
       "      <td>4879.0</td>\n",
       "      <td>4501.0</td>\n",
       "      <td>7173.0</td>\n",
       "      <td>9062.0</td>\n",
       "      <td>5065.0</td>\n",
       "      <td>6663.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20829.0</td>\n",
       "      <td>29957.0</td>\n",
       "      <td>10267.0</td>\n",
       "      <td>32161.0</td>\n",
       "      <td>23875.0</td>\n",
       "      <td>11274.0</td>\n",
       "      <td>20311.0</td>\n",
       "      <td>16611.0</td>\n",
       "      <td>30284.0</td>\n",
       "      <td>32940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20722957809749969</th>\n",
       "      <td>133.0</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>5636.0</td>\n",
       "      <td>5524.0</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>7093.0</td>\n",
       "      <td>5009.0</td>\n",
       "      <td>8118.0</td>\n",
       "      <td>6843.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25825.0</td>\n",
       "      <td>25259.0</td>\n",
       "      <td>21567.0</td>\n",
       "      <td>26184.0</td>\n",
       "      <td>21557.0</td>\n",
       "      <td>20224.0</td>\n",
       "      <td>8124.0</td>\n",
       "      <td>19956.0</td>\n",
       "      <td>34195.0</td>\n",
       "      <td>40838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23207904112410946</th>\n",
       "      <td>400.0</td>\n",
       "      <td>2180.0</td>\n",
       "      <td>3849.0</td>\n",
       "      <td>6373.0</td>\n",
       "      <td>7290.0</td>\n",
       "      <td>3279.0</td>\n",
       "      <td>8364.0</td>\n",
       "      <td>5616.0</td>\n",
       "      <td>4806.0</td>\n",
       "      <td>6530.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23058.0</td>\n",
       "      <td>28815.0</td>\n",
       "      <td>23135.0</td>\n",
       "      <td>28529.0</td>\n",
       "      <td>21758.0</td>\n",
       "      <td>18757.0</td>\n",
       "      <td>19890.0</td>\n",
       "      <td>18061.0</td>\n",
       "      <td>26777.0</td>\n",
       "      <td>35709.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8438939060540919</th>\n",
       "      <td>784.0</td>\n",
       "      <td>3097.0</td>\n",
       "      <td>3198.0</td>\n",
       "      <td>3980.0</td>\n",
       "      <td>3299.0</td>\n",
       "      <td>6460.0</td>\n",
       "      <td>8526.0</td>\n",
       "      <td>7905.0</td>\n",
       "      <td>7195.0</td>\n",
       "      <td>6002.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26349.0</td>\n",
       "      <td>19767.0</td>\n",
       "      <td>21466.0</td>\n",
       "      <td>23008.0</td>\n",
       "      <td>21104.0</td>\n",
       "      <td>20068.0</td>\n",
       "      <td>27251.0</td>\n",
       "      <td>37493.0</td>\n",
       "      <td>34363.0</td>\n",
       "      <td>42049.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23051156318899201</th>\n",
       "      <td>64.0</td>\n",
       "      <td>3779.0</td>\n",
       "      <td>4611.0</td>\n",
       "      <td>6099.0</td>\n",
       "      <td>5923.0</td>\n",
       "      <td>4611.0</td>\n",
       "      <td>6253.0</td>\n",
       "      <td>4942.0</td>\n",
       "      <td>6337.0</td>\n",
       "      <td>9766.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24736.0</td>\n",
       "      <td>26267.0</td>\n",
       "      <td>21957.0</td>\n",
       "      <td>26660.0</td>\n",
       "      <td>21262.0</td>\n",
       "      <td>20322.0</td>\n",
       "      <td>15674.0</td>\n",
       "      <td>18572.0</td>\n",
       "      <td>47771.0</td>\n",
       "      <td>39485.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0       1       2       3       4       5       6    \\\n",
       "0                                                                           \n",
       "9288284844333351   1003.0  3170.0  4629.0  4852.0  4879.0  4501.0  7173.0   \n",
       "20722957809749969   133.0  3219.0  3997.0  5636.0  5524.0  4019.0  7093.0   \n",
       "23207904112410946   400.0  2180.0  3849.0  6373.0  7290.0  3279.0  8364.0   \n",
       "8438939060540919    784.0  3097.0  3198.0  3980.0  3299.0  6460.0  8526.0   \n",
       "23051156318899201    64.0  3779.0  4611.0  6099.0  5923.0  4611.0  6253.0   \n",
       "\n",
       "                      7       8       9     ...         246      247      248  \\\n",
       "0                                           ...                                 \n",
       "9288284844333351   9062.0  5065.0  6663.0   ...     20829.0  29957.0  10267.0   \n",
       "20722957809749969  5009.0  8118.0  6843.0   ...     25825.0  25259.0  21567.0   \n",
       "23207904112410946  5616.0  4806.0  6530.0   ...     23058.0  28815.0  23135.0   \n",
       "8438939060540919   7905.0  7195.0  6002.0   ...     26349.0  19767.0  21466.0   \n",
       "23051156318899201  4942.0  6337.0  9766.0   ...     24736.0  26267.0  21957.0   \n",
       "\n",
       "                       249      250      251      252      253      254  \\\n",
       "0                                                                         \n",
       "9288284844333351   32161.0  23875.0  11274.0  20311.0  16611.0  30284.0   \n",
       "20722957809749969  26184.0  21557.0  20224.0   8124.0  19956.0  34195.0   \n",
       "23207904112410946  28529.0  21758.0  18757.0  19890.0  18061.0  26777.0   \n",
       "8438939060540919   23008.0  21104.0  20068.0  27251.0  37493.0  34363.0   \n",
       "23051156318899201  26660.0  21262.0  20322.0  15674.0  18572.0  47771.0   \n",
       "\n",
       "                       255  \n",
       "0                           \n",
       "9288284844333351   32940.0  \n",
       "20722957809749969  40838.0  \n",
       "23207904112410946  35709.0  \n",
       "8438939060540919   42049.0  \n",
       "23051156318899201  39485.0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.475673874944\n"
     ]
    }
   ],
   "source": [
    "nb_multinomial_pca = MultinomialNB()\n",
    "nb_multinomial_pca.fit(training_z, training_labels)\n",
    "\n",
    "validation_pred = nb_multinomial_pca.predict(validation_z)\n",
    "accuracy = nb_multinomial_pca.score(validation_z, validation_labels)\n",
    "print(accuracy)\n",
    "\n",
    "alg = \"NBmultinomial\"\n",
    "uids = pandas.DataFrame(validation_labels).rename(columns={1:'true'}).join( pandas.DataFrame(validation_pred, index=validation.index, columns=['pred']) ) \n",
    "counts = uids.groupby(['true','pred']).size().unstack().transpose()\n",
    "c = counts.reset_index(drop=True).transpose().reset_index(drop=True).transpose() \n",
    "distance_error_counts = how_wrong_can_we_classify_user.reset_index(drop=True).transpose().reset_index(drop=True).transpose().multiply(c)\n",
    "distance_error = distance_error_counts.sum().sum()/counts.sum().sum()\n",
    "efficacy_validation.loc['accuracy',alg] = accuracy\n",
    "efficacy_validation.loc['weighted-error',alg] = distance_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation class predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15740002770882921</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20076326138989514</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13832899909391491</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23061239623893428</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19447249592914859</th>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "0                     \n",
       "15740002770882921  672\n",
       "20076326138989514  672\n",
       "13832899909391491  672\n",
       "23061239623893428  672\n",
       "19447249592914859  680"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Validation class predictions:\")\n",
    "pandas.DataFrame(validation_pred, index=validation_features.index).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46995621030652784"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: Naive Bayes Bernoulli (no PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.119727706385\n"
     ]
    }
   ],
   "source": [
    "oos_pred = nb_bernoulli.predict(oos_features)\n",
    "accuracy = nb_bernoulli.score(oos_features, oos_labels)\n",
    "print(accuracy)\n",
    "\n",
    "alg = \"NBbernoulli\"\n",
    "uids = pandas.DataFrame(oos_labels, columns=['true']).join(pandas.DataFrame(oos_pred,columns=['pred'])) \n",
    "counts = uids.groupby(['true','pred']).size().unstack().transpose()\n",
    "c = counts.reset_index(drop=True).transpose().reset_index(drop=True).transpose() \n",
    "distance_error_counts = how_wrong_can_we_classify_user.reset_index(drop=True).transpose().reset_index(drop=True).transpose().multiply(c)\n",
    "distance_error = distance_error_counts.sum().sum()/counts.sum().sum()\n",
    "efficacy_oos.loc['accuracy',alg] = accuracy\n",
    "efficacy_oos.loc['weighted-error',alg] = distance_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: Linear Discriminant Analysis (no PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12776749792\n"
     ]
    }
   ],
   "source": [
    "oos_pred = lda.predict(oos_features)\n",
    "accuracy = lda.score(oos_features,oos_labels)\n",
    "print(accuracy)\n",
    "\n",
    "alg = \"LDA\"\n",
    "uids = pandas.DataFrame(oos_labels, columns=['true']).join(pandas.DataFrame(oos_pred,columns=['pred'])) \n",
    "counts = uids.groupby(['true','pred']).size().unstack().transpose()\n",
    "c = counts.reset_index(drop=True).transpose().reset_index(drop=True).transpose() \n",
    "distance_error_counts = how_wrong_can_we_classify_user.reset_index(drop=True).transpose().reset_index(drop=True).transpose().multiply(c)\n",
    "distance_error = distance_error_counts.sum().sum()/counts.sum().sum()\n",
    "efficacy_oos.loc['accuracy',alg] = accuracy\n",
    "efficacy_oos.loc['weighted-error',alg] = distance_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: Linear Discriminant Analysis (after PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0937070297248\n"
     ]
    }
   ],
   "source": [
    "oos_pred = lda.predict(oos_transformed)\n",
    "accuracy = lda.score(oos_transformed,oos_labels)\n",
    "print(accuracy)\n",
    "\n",
    "alg = \"LDApca\"\n",
    "uids = pandas.DataFrame(oos_labels, columns=['true']).join(pandas.DataFrame(oos_pred,columns=['pred'])) \n",
    "counts = uids.groupby(['true','pred']).size().unstack().transpose()\n",
    "c = counts.reset_index(drop=True).transpose().reset_index(drop=True).transpose() \n",
    "distance_error_counts = how_wrong_can_we_classify_user.reset_index(drop=True).transpose().reset_index(drop=True).transpose().multiply(c)\n",
    "distance_error = distance_error_counts.sum().sum()/counts.sum().sum()\n",
    "efficacy_oos.loc['accuracy',alg] = accuracy\n",
    "efficacy_oos.loc['weighted-error',alg] = distance_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: Naive Bayes Gaussian (after PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0937070297248\n"
     ]
    }
   ],
   "source": [
    "oos_transformed = pca.transform(oos_features)\n",
    "oos_pred = lda.predict(oos_transformed)\n",
    "accuracy = lda.score(oos_transformed,oos_labels)\n",
    "print(accuracy)\n",
    "\n",
    "alg = \"NBgaussian\"\n",
    "uids = pandas.DataFrame(oos_labels, columns=['true']).join(pandas.DataFrame(oos_pred,columns=['pred'])) \n",
    "counts = uids.groupby(['true','pred']).size().unstack().transpose()\n",
    "c = counts.reset_index(drop=True).transpose().reset_index(drop=True).transpose() \n",
    "distance_error_counts = how_wrong_can_we_classify_user.reset_index(drop=True).transpose().reset_index(drop=True).transpose().multiply(c)\n",
    "distance_error = distance_error_counts.sum().sum()/counts.sum().sum()\n",
    "efficacy_oos.loc['accuracy',alg] = accuracy\n",
    "efficacy_oos.loc['weighted-error',alg] = distance_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: Naive Bayes Multinomial (after PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0772132344204\n"
     ]
    }
   ],
   "source": [
    "oos_z = pandas.DataFrame(oos_transformed).apply(lambda x: numpy.floor((x-x.min())*(1000./x.var()))) \n",
    "oos_pred = nb_multinomial_pca.predict(oos_z)\n",
    "accuracy = nb_multinomial_pca.score(oos_z, oos_labels)\n",
    "print(accuracy)\n",
    "\n",
    "alg = \"NBmultinomial\"\n",
    "uids = pandas.DataFrame(oos_labels, columns=['true']).join(pandas.DataFrame(oos_pred,columns=['pred'])) \n",
    "counts = uids.groupby(['true','pred']).size().unstack().transpose()\n",
    "c = counts.reset_index(drop=True).transpose().reset_index(drop=True).transpose() \n",
    "distance_error_counts = how_wrong_can_we_classify_user.reset_index(drop=True).transpose().reset_index(drop=True).transpose().multiply(c)\n",
    "distance_error = distance_error_counts.sum().sum()/counts.sum().sum()\n",
    "efficacy_oos.loc['accuracy',alg] = accuracy\n",
    "efficacy_oos.loc['weighted-error',alg] = distance_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficacy Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficacy_validation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NBbernoulli</th>\n",
       "      <th>LDA</th>\n",
       "      <th>NBgaussian</th>\n",
       "      <th>NBmultinomial</th>\n",
       "      <th>LDApca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.290439</td>\n",
       "      <td>0.489363</td>\n",
       "      <td>0.262479</td>\n",
       "      <td>0.469088</td>\n",
       "      <td>0.114341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted-error</th>\n",
       "      <td>0.328481</td>\n",
       "      <td>0.196670</td>\n",
       "      <td>0.358640</td>\n",
       "      <td>0.202382</td>\n",
       "      <td>0.444431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NBbernoulli       LDA  NBgaussian  NBmultinomial    LDApca\n",
       "accuracy           0.290439  0.489363    0.262479       0.469088  0.114341\n",
       "weighted-error     0.328481  0.196670    0.358640       0.202382  0.444431"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficacy_oos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NBbernoulli</th>\n",
       "      <th>LDA</th>\n",
       "      <th>NBgaussian</th>\n",
       "      <th>NBmultinomial</th>\n",
       "      <th>LDApca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.119728</td>\n",
       "      <td>0.127767</td>\n",
       "      <td>0.093707</td>\n",
       "      <td>0.077213</td>\n",
       "      <td>0.093707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted-error</th>\n",
       "      <td>0.467571</td>\n",
       "      <td>0.450206</td>\n",
       "      <td>0.434996</td>\n",
       "      <td>0.693844</td>\n",
       "      <td>0.434996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NBbernoulli       LDA  NBgaussian  NBmultinomial    LDApca\n",
       "accuracy           0.119728  0.127767    0.093707       0.077213  0.093707\n",
       "weighted-error     0.467571  0.450206    0.434996       0.693844  0.434996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"efficacy_validation\")\n",
    "display(efficacy_validation)\n",
    "\n",
    "print(\"efficacy_oos\")\n",
    "display(efficacy_oos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
